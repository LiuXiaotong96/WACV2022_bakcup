{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet,Bottleneck,BasicBlock\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import sys\n",
    "sys.path.append(\"../_code\")\n",
    "from color_lib import RGBmean,RGBstdv\n",
    "from Reader import ImageReader\n",
    "from Utils import norml2\n",
    "from similarity_ops import *\n",
    "from image_ops import *\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "from types import MethodType\n",
    "import pickle\n",
    "import matplotlib as mpt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "from powerful_benchmarker import architectures\n",
    "from powerful_benchmarker import datasets\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "from pytorch_metric_learning.testers import GlobalEmbeddingSpaceTester\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import powerful_benchmarker\n",
    "import pytorch_metric_learning\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "print(\"powerful_benchmarker.__version__\", powerful_benchmarker.__version__)\n",
    "print(\"pytorch_metric_learning.__version__\", pytorch_metric_learning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# get colormap\n",
    "ncolors = 256\n",
    "color_array = plt.get_cmap('jet')(range(ncolors))\n",
    "# change alpha values\n",
    "#color_array[:,-1] = np.linspace(0.0,1.0,ncolors)\n",
    "#color_array[127:] = [0,0,0,0]\n",
    "\n",
    "# create a colormap object\n",
    "map_object = LinearSegmentedColormap.from_list(name='jet_alpha',colors=color_array)\n",
    "\n",
    "# register this new colormap with matplotlib\n",
    "plt.register_cmap(cmap=map_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "class ConvertToBGR(object):\n",
    "    \"\"\"\n",
    "    Converts a PIL image from RGB to BGR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img):\n",
    "        r, g, b = img.split()\n",
    "        img = Image.merge(\"RGB\", (b, g, r))\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}()\".format(self.__class__.__name__)\n",
    "\n",
    "\n",
    "class Multiplier(object):\n",
    "    def __init__(self, multiple):\n",
    "        self.multiple = multiple\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img*self.multiple\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}(multiple={})\".format(self.__class__.__name__, self.multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BNInception(\n",
       "  (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_relu_7x7): ReLU(inplace=True)\n",
       "  (pool1_3x3_s2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_relu_3x3): ReLU(inplace=True)\n",
       "  (pool2_3x3_s2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_3c_3x3_reduce): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_3c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_3c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_3c_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_3c_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_3c_pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_4a_1x1): Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_1x1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_4a_3x3_reduce): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4a_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_4a_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4a_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_4a_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_4a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4a_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_4b_1x1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_1x1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_4b_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4b_3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_4b_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4b_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_4b_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_4b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4b_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_4c_1x1): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_1x1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_4c_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_4c_double_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_double_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4c_double_3x3_1): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_double_3x3_1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_4c_double_3x3_2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_double_3x3_2_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_4c_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4c_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_4d_1x1): Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_1x1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_4d_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4d_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_4d_double_3x3_reduce): Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4d_double_3x3_1): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_double_3x3_1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_4d_double_3x3_2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_double_3x3_2_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_4d_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4d_pool_proj): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_4e_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4e_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4e_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_4e_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_4e_double_3x3_reduce): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4e_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_4e_double_3x3_1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4e_double_3x3_1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_4e_double_3x3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_4e_double_3x3_2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_4e_pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_5a_1x1): Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_5a_3x3_reduce): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_5a_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_5a_double_3x3_reduce): Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_5a_double_3x3_1): Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_5a_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_5a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_5a_pool_proj): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_pool_proj): ReLU(inplace=True)\n",
       "  (inception_5b_1x1): Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_1x1): ReLU(inplace=True)\n",
       "  (inception_5b_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_5b_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_3x3): ReLU(inplace=True)\n",
       "  (inception_5b_double_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "  (inception_5b_double_3x3_1): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  (inception_5b_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_2): ReLU(inplace=True)\n",
       "  (inception_5b_pool): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_5b_pool_proj): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_pool_proj): ReLU(inplace=True)\n",
       "  (global_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data='CAR'\n",
    "tra_or_val = 'val'\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "#model_epshn = torch.load('pretrained_model/'+Data+'/ArcFace/model.pth')\n",
    "\n",
    "#model_triplet = torch.load('pretrained_model/'+Data+'/Triplet/model.pth')\n",
    "#model_arcface = torch.load('./_result/'+Data+'/Arcface/model.pth')\n",
    "# state_dict_npairs = torch.load('../_result_vis/CUB_R18_Npair/0/model.pth').state_dict()\n",
    "# state_dict_nn = torch.load('../_result_vis/CUB_R18_G16/0/model.pth').state_dict()\n",
    "\n",
    "output_folder = os.path.join(Data,'PCA',tra_or_val,'top_results')\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "model_name = 'bninception'\n",
    "model_epshn = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "model_epshn.last_linear = nn.Linear(1024,128)\n",
    "    \n",
    "trunk=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/trunk_best.pth\")\n",
    "embedder=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/embedder_best.pth\")\n",
    "\n",
    "# trunk=torch.load(\"../fair_exp/experiments/ArcFace_CUB/Test50_50_Partitions4_0/saved_models/trunk_best.pth\")\n",
    "# embedder=torch.load(\"../fair_exp/experiments/ArcFace_CUB/Test50_50_Partitions4_0/saved_models/embedder_best.pth\")\n",
    "\n",
    "trunk.update(embedder)\n",
    "trunk.pop('net.0.weight')\n",
    "trunk.pop('net.0.bias')\n",
    "model_epshn.load_state_dict(trunk)    \n",
    "\n",
    "#data_dict = torch.load('CUB_toy.pth')\n",
    "data_dict = torch.load('/pless_nfs/home/datasets/'+Data+'/data_dict_emb.pth')\n",
    "# src='/pless_nfs/home/datasets/'+Data+'/data_e/'##\n",
    "# data_dict = {p:{os.path.basename(d):glob(d+'/*.jpg') for d in glob(src+p+'/*')} for p in ['tra', 'val']}\n",
    "\n",
    "embed_size=128\n",
    "\n",
    "data_transforms = transforms.Compose([ConvertToBGR(),\n",
    "                                      transforms.Resize(454),\n",
    "                                      transforms.CenterCrop(454),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      Multiplier(255),\n",
    "                                      transforms.Normalize(mean = [104, 117, 128], \n",
    "                                                     std = [1, 1, 1])])\n",
    "\n",
    "dsets = ImageReader(data_dict[tra_or_val], data_transforms)\n",
    "\n",
    "model_epshn = model_epshn.cuda()\n",
    "model_epshn.train(False)\n",
    "\n",
    "#model_triplet = model_triplet.cuda()\n",
    "#model_triplet = model_triplet\n",
    "\n",
    "# model_arcface.avgpool = model_npairs.avgpool\n",
    "# model_arcface = model_arcface.cuda()\n",
    "# model_arcface.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from gradcam import GradCam\n",
    "importlib.reload(sys.modules['gradcam'])\n",
    "from gradcam import GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=model_epshn, feature_module=model_epshn,target_layer_names=[\"global_pool\"], use_cuda='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "def feature_map_hook(module, input, output):\n",
    "    embeddings.append(input[0])\n",
    "\n",
    "def register_embedding_hooks_vgg(model):\n",
    "    for i,module in enumerate(model.children()):\n",
    "        # If the layer has children of its own, recursively traverse\n",
    "#         if list(module.children()):\n",
    "#             register_embedding_hooks_vgg(module)\n",
    "#         # If a pooling layer, register a hook\n",
    "#         elif isinstance(module, nn.MaxPool2d):# or isinstance(module, nn.AdaptiveAvgPool2d):\n",
    "#             print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "#             module.register_forward_hook(feature_map_hook)\n",
    "        if isinstance(module, nn.AdaptiveAvgPool2d):\n",
    "            print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "            module.register_forward_hook(feature_map_hook)\n",
    "        # If a strided convolution layer, register a hook\n",
    "        elif isinstance(module,nn.AvgPool2d):\n",
    "            print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "            module.register_forward_hook(feature_map_hook)\n",
    "#         elif isinstance(module, nn.Conv2d) and module.stride > (1,1):\n",
    "#             print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "#             module.register_forward_hook(feature_map_hook)\n",
    "\n",
    "def register_hooks_resnet(model):\n",
    "    for i,module in enumerate(model.children()):\n",
    "        if list(module.children()):\n",
    "            print(f\"Registering hook to Layer ({i})\")\n",
    "            module.register_forward_hook(feature_map_hook)\n",
    "        elif isinstance(module, nn.MaxPool2d):# or isinstance(module, nn.AdaptiveAvgPool2d):\n",
    "            print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "            module.register_forward_hook(feature_map_hook)\n",
    "        elif isinstance(module, nn.AdaptiveAvgPool2d):\n",
    "            print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "            module.register_forward_hook(feature_map_hook)\n",
    "        elif isinstance(module,nn.AvgPool2d):\n",
    "            print(f\"Registering hook to Layer ({i}) {module}\")\n",
    "            module.register_forward_hook(feature_map_hook)\n",
    "\n",
    "def activation_map(maps,input_size=224,interp_mode='bilinear'):\n",
    "#     amap = []\n",
    "#     amap = [F.interpolate(torch.sum(x,dim=1).unsqueeze(1), size=input_size,mode=interp_mode) for x in maps]\n",
    "#     amap = torch.cat(amap, dim=1)\n",
    "#     amap = torch.sum(amap,dim=1)\n",
    "\n",
    "    amap = torch.norm(maps[0],dim=1).unsqueeze(1)\n",
    "    amap = F.interpolate(amap, size=input_size,mode=interp_mode).squeeze()\n",
    "    return amap\n",
    "\n",
    "\n",
    "def embed(dsets,whichModel,imgsize=454,interp_mode='nearest'):\n",
    "    global embeddings\n",
    "    whichModel.train(False)\n",
    "    dataLoader = torch.utils.data.DataLoader(dsets, batch_size=20, sampler=SequentialSampler(dsets), num_workers=12)\n",
    "    V,M,L,S,M_f = [],[],[],[],[]\n",
    "    try:\n",
    "        fclayer = whichModel.last_linear\n",
    "    except:\n",
    "        fclayer = whichModel.fc\n",
    "    for data in dataLoader:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            inputs_bt, labels_bt = data['data'], data['label']\n",
    "            fvec = whichModel(inputs_bt.cuda())\n",
    "            fvec = (fvec.T/torch.norm(fvec,dim=1)).T\n",
    "            fmap = embeddings[-1]\n",
    "            final_map = fclayer(fmap.detach().clone().permute(0,2,3,1)).permute(0,3,1,2)\n",
    "        V.extend(fvec.cpu().numpy())\n",
    "        M.extend(fmap.cpu().numpy())\n",
    "        M_f.extend(final_map.cpu().numpy())\n",
    "        L.extend(labels_bt.numpy())\n",
    "        S.extend(activation_map([embeddings[-1]],input_size=imgsize,interp_mode=interp_mode).cpu().numpy())\n",
    "        embeddings = []\n",
    "    maps_epshn = np.moveaxis(np.array(M),1,3)\n",
    "    feats_epshn = np.array(V)\n",
    "    labels = np.array(L)\n",
    "    act_map = np.array(S)\n",
    "    maps_final = np.moveaxis(np.array(M_f),1,3)\n",
    "    return feats_epshn, maps_epshn,act_map, labels,maps_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_vector(Data,loss,tra_or_val = 'val',imgsize=454):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "    dataname = ''\n",
    "    if Data == 'CUB':\n",
    "        dataname = '_CUB'\n",
    "    model_name = 'bninception'\n",
    "    model_epshn = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "    model_epshn.last_linear = nn.Linear(1024,128)\n",
    "\n",
    "    # trunk=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/trunk_best36.pth\")\n",
    "    # embedder=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/embedder_best36.pth\")\n",
    " \n",
    "    trunk=torch.load(\"../fair_exp/experiments/\"+loss+dataname+\"/Test50_50_Partitions4_0/saved_models/trunk_best.pth\")\n",
    "    embedder=torch.load(\"../fair_exp/experiments/\"+loss+dataname+\"/Test50_50_Partitions4_0/saved_models/embedder_best.pth\")\n",
    "\n",
    "    trunk.update(embedder)\n",
    "    trunk.pop('net.0.weight')\n",
    "    trunk.pop('net.0.bias')\n",
    "    model_epshn.load_state_dict(trunk)  \n",
    "    #model_arcface = torch.load('./_result/'+Data+'/Arcface/model.pth')\n",
    "    # state_dict_npairs = torch.load('../_result_vis/CUB_R18_Npair/0/model.pth').state_dict()\n",
    "    # state_dict_nn = torch.load('../_result_vis/CUB_R18_G16/0/model.pth').state_dict()\n",
    "    data_dict = torch.load('/pless_nfs/home/datasets/'+Data+'/data_dict_emb.pth')\n",
    "    # src='/pless_nfs/home/datasets/'+Data+'/data_e/'##\n",
    "    # data_dict = {p:{os.path.basename(d):glob(d+'/*.jpg') for d in glob(src+p+'/*')} for p in ['tra', 'val']}\n",
    "\n",
    "    embed_size=256\n",
    "\n",
    "    data_transforms = transforms.Compose([ConvertToBGR(),\n",
    "                                          transforms.Resize(454),\n",
    "                                          transforms.CenterCrop(454),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          Multiplier(255),\n",
    "                                          transforms.Normalize(RGBmean['Imagenet'], RGBstdv['Imagenet'])])\n",
    "\n",
    "    dsets = ImageReader(data_dict[tra_or_val], data_transforms)\n",
    "\n",
    "    model_epshn = model_epshn.cuda()\n",
    "    model_epshn.train(False)\n",
    "    feats_epshn, maps_epshn, labels, epshn_weighs = embed(dsets,model_epshn,0,imgsize=454)\n",
    "    featsavepath = os.path.join(Data,'savedata',tra_or_val,loss)\n",
    "    if not os.path.exists(featsavepath):\n",
    "        os.makedirs(featsavepath)\n",
    "#     torch.save(feats_epshn,featsavepath+'feats.pth')\n",
    "#     torch.save(maps_epshn,featsavepath+'maps.pth')\n",
    "#     torch.save(labels,featsavepath+'labels.pth')\n",
    "    return feats_epshn,maps_epshn,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_vector_phase(phase='',tra_or_val = 'val',imgsize=454):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "    dataname = ''\n",
    "    if Data == 'CUB':\n",
    "        dataname = '_CUB'\n",
    "    model_name = 'bninception'\n",
    "    model_epshn = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "    model_epshn.last_linear = nn.Linear(1024,128)\n",
    "\n",
    "    # trunk=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/trunk_best36.pth\")\n",
    "    # embedder=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/embedder_best36.pth\")\n",
    " \n",
    "    trunk=torch.load(\"../fair_exp/experiments/training_process_CUB_ArcFace/trunk_best\"+str(phase)+\".pth\")\n",
    "    embedder=torch.load(\"../fair_exp/experiments/training_process_CUB_ArcFace/embedder_best\"+str(phase)+\".pth\")\n",
    "\n",
    "    trunk.update(embedder)\n",
    "    trunk.pop('net.0.weight')\n",
    "    trunk.pop('net.0.bias')\n",
    "    model_epshn.load_state_dict(trunk)  \n",
    "    #model_arcface = torch.load('./_result/'+Data+'/Arcface/model.pth')\n",
    "    # state_dict_npairs = torch.load('../_result_vis/CUB_R18_Npair/0/model.pth').state_dict()\n",
    "    # state_dict_nn = torch.load('../_result_vis/CUB_R18_G16/0/model.pth').state_dict()\n",
    "    data_dict = torch.load('/pless_nfs/home/datasets/'+Data+'/data_dict_emb.pth')\n",
    "    # src='/pless_nfs/home/datasets/'+Data+'/data_e/'##\n",
    "    # data_dict = {p:{os.path.basename(d):glob(d+'/*.jpg') for d in glob(src+p+'/*')} for p in ['tra', 'val']}\n",
    "\n",
    "    embed_size=256\n",
    "\n",
    "    data_transforms = transforms.Compose([ConvertToBGR(),\n",
    "                                          transforms.Resize(454),\n",
    "                                          transforms.CenterCrop(454),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          Multiplier(255),\n",
    "                                          transforms.Normalize(RGBmean['Imagenet'], RGBstdv['Imagenet'])])\n",
    "\n",
    "    dsets = ImageReader(data_dict[tra_or_val], data_transforms)\n",
    "\n",
    "    model_epshn = model_epshn.cuda()\n",
    "    model_epshn.train(False)\n",
    "    feats_epshn, maps_epshn, labels, epshn_weighs = embed(dsets,model_epshn,0,imgsize=454)\n",
    "    #featsavepath = os.path.join(Data,'savedata',tra_or_val,loss)\n",
    "    #if not os.path.exists(featsavepath):\n",
    "    #    os.makedirs(featsavepath)\n",
    "#     torch.save(feats_epshn,featsavepath+'feats.pth')\n",
    "#     torch.save(maps_epshn,featsavepath+'maps.pth')\n",
    "#     torch.save(labels,featsavepath+'labels.pth')\n",
    "    return feats_epshn,maps_epshn,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "Data='CAR'\n",
    "tra_or_val = 'val'\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#model_epshn = torch.load('pretrained_model/'+Data+'/ArcFace/model.pth')\n",
    "\n",
    "#model_triplet = torch.load('pretrained_model/'+Data+'/Triplet/model.pth')\n",
    "#model_arcface = torch.load('./_result/'+Data+'/Arcface/model.pth')\n",
    "# state_dict_npairs = torch.load('../_result_vis/CUB_R18_Npair/0/model.pth').state_dict()\n",
    "# state_dict_nn = torch.load('../_result_vis/CUB_R18_G16/0/model.pth').state_dict()\n",
    "\n",
    "output_folder = os.path.join(Data,'PCA_pooling_training',tra_or_val,'top_results')\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "model_name = 'bninception'\n",
    "model_ori =torch.load('./pretrained_model/CAR/ArcFace/model.pth')  \n",
    "\n",
    "model_pca = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "model_pca.last_linear = nn.Linear(1024,128)\n",
    "    \n",
    "# trunk=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/trunk_best36.pth\")\n",
    "# embedder=torch.load(\"../fair_exp/experiments/ArcFace/Test50_50_Partitions4_0/saved_models/embedder_best36.pth\")\n",
    "\n",
    "trunk=torch.load(\"/pless_nfs/home/liuxiaotong2017/fair_exp/experiments/PCA/CAR_optim/ArcFace/PCA/CAR_optim/ArcFace/7/Test50_50_Partitions4_0/saved_models/trunk_best32.pth\")\n",
    "embedder=torch.load(\"/pless_nfs/home/liuxiaotong2017/fair_exp/experiments/PCA/CAR_optim/ArcFace/PCA/CAR_optim/ArcFace/7/Test50_50_Partitions4_0/saved_models/embedder_best32.pth\")\n",
    "\n",
    "fcparam = OrderedDict()\n",
    "for key in embedder:\n",
    "    if 'weight' in key:\n",
    "        print(key)\n",
    "        fcparam[key] = embedder[key][:,3*1024:]\n",
    "    if 'bias' in key:\n",
    "        print(key)\n",
    "        fcparam[key] = embedder[key]\n",
    "\n",
    "trunk.update(fcparam)\n",
    "# trunk.pop('net.0.weight')\n",
    "# trunk.pop('net.0.bias')\n",
    "model_pca.load_state_dict(trunk)  \n",
    "    \n",
    "data_dict = torch.load('/pless_nfs/home/datasets/'+Data+'/data_dict_emb.pth')\n",
    "# src='/pless_nfs/home/datasets/'+Data+'/data_e/'##\n",
    "# data_dict = {p:{os.path.basename(d):glob(d+'/*.jpg') for d in glob(src+p+'/*')} for p in ['tra', 'val']}\n",
    "\n",
    "embed_size=128\n",
    "\n",
    "data_transforms = transforms.Compose([ConvertToBGR(),\n",
    "                                      transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(256),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      Multiplier(255),\n",
    "                                      transforms.Normalize(RGBmean['Imagenet'], RGBstdv['Imagenet'])])\n",
    "\n",
    "dsets = ImageReader(data_dict[tra_or_val], data_transforms)\n",
    "\n",
    "model_ori = model_ori.cuda()\n",
    "model_ori.train(False)\n",
    "\n",
    "model_pca = model_pca.cuda()\n",
    "model_pca.train(False)\n",
    "\n",
    "#model_triplet = model_triplet.cuda()\n",
    "#model_triplet = model_triplet\n",
    "\n",
    "# model_arcface.avgpool = model_npairs.avgpool\n",
    "# model_arcface = model_arcface.cuda()\n",
    "# model_arcface.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 start!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_vector_phase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f7cd2ca60143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'start!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfeats_epshn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaps_epshn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vector_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtra_or_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tra'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m454\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_epshn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaps_epshn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_vector_phase' is not defined"
     ]
    }
   ],
   "source": [
    "feats = []\n",
    "maps = []\n",
    "lables = []\n",
    "# for Data in ['CAR']:\n",
    "#     for loss in ['ArcFace','Triplet','ProxyNCA','MS']:\n",
    "    #for loss in ['MS']:\n",
    "for phase in [0,2,4,6,12]:\n",
    "    print(phase,'start!')\n",
    "    feats_epshn,maps_epshn,labels = get_vector_phase(phase,tra_or_val = 'tra', imgsize=454)\n",
    "    feats.append(feats_epshn)\n",
    "    maps.append(maps_epshn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook to Layer (3) MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
      "Registering hook to Layer (10) MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
      "Registering hook to Layer (29) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (51) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (70) MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
      "Registering hook to Layer (89) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (111) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (133) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (155) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (174) MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
      "Registering hook to Layer (193) AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "Registering hook to Layer (215) MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
      "Registering hook to Layer (219) AvgPool2d(kernel_size=7, stride=1, padding=0)\n"
     ]
    }
   ],
   "source": [
    "register_hooks_resnet(model_epshn)\n",
    "feats_epshn, maps_epshn,act_map, labels,_ = embed(dsets,model_epshn,imgsize=256,interp_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8131, 14, 14, 1024)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps_epshn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feats_epshn = torch.load('./WACV2022/Comparison/CUB/val/feats_epehn.pth')\n",
    "act_map = torch.load('./WACV2022/Comparison/CUB/val/act_map.pth')\n",
    "with open('./WACV2022/Comparison/CUB/val/CUB_val_conv_14*14.pth', 'rb') as handle:\n",
    "    maps_epshn = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_epshn = torch.load('./WACV2022/Comparison/CAR/val/feats_epehn.pth')\n",
    "act_map = torch.load('./WACV2022/Comparison/CAR/val/act_map.pth')\n",
    "with open('./WACV2022/Comparison/CAR/val/CAR_val_conv_14*14.pth', 'rb') as handle:\n",
    "    maps_epshn = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feats_epshn = torch.load('./WACV2022/Comparison/CAR/feats_epehn.pth')\n",
    "act_map = torch.load('./WACV2022/Comparison/CAR/act_map.pth')\n",
    "with open('./WACV2022/Comparison/CAR/CAR_tra_conv_14*14.pth', 'rb') as handle:\n",
    "    maps_epshn = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8054, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feats_epshn = torch.load('./WACV2022/Comparison/feats_epehn.pth')\n",
    "act_map = torch.load('./WACV2022/Comparison/CUB/act_map.pth')\n",
    "with open('/pless_nfs/home/liuxiaotong2017/../share_projects/CUB_14*14_conv/Arcface_CUB_tra_conv_14*14.pkl', 'rb') as f:\n",
    "    maps_epshn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(list(dsets.idx_to_class.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms2 = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(256)])\n",
    "dsets2 = ImageReader(data_dict[tra_or_val], data_transforms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image_and_heatmap(img,heatmap,lower_bound,upper_bound,greyscale = True):\n",
    "    \"\"\"\n",
    "    Takes in a numpy array for an image and the similarity heatmap.\n",
    "    Blends the two images together and returns a np array of the blended image.\n",
    "    \"\"\"\n",
    "    register_colorbar()\n",
    "    cmap = plt.get_cmap('jet_alpha')# colormap for the heatmap\n",
    "    heatmap = heatmap - lower_bound \n",
    "    heatmap /= upper_bound\n",
    "#     heatmap = cmap(np.max(heatmap)-heatmap)\n",
    "    heatmap = cmap(heatmap)\n",
    "    if np.max(heatmap) < 255.:\n",
    "        heatmap *= 255\n",
    "\n",
    "    heatmap_img = cv2.resize(heatmap,(256,256),interpolation = cv2.INTER_NEAREST)\n",
    "    #heatmap_img = cv2.resize(heatmap,(256,256))\n",
    "    bg = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "    if greyscale == True:\n",
    "        matrix = (0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0)\n",
    "        bg = bg.convert('RGB',matrix)\n",
    "    fg = Image.fromarray(heatmap_img.astype('uint8')).convert('RGB')\n",
    "    outIm = np.array(Image.blend(bg,fg,alpha=0.5))\n",
    "    return outIm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image_and_heatmap_rgb(img,heatmap,greyscale = True):\n",
    "    \"\"\"\n",
    "    Takes in a numpy array for an image and the similarity heatmap.\n",
    "    Blends the two images together and returns a np array of the blended image.\n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    heatmap = cmap(np.max(heatmap)-heatmap)\n",
    "    if np.max(heatmap) < 255.:\n",
    "        heatmap *= 255\n",
    "    #heatmap_img = cv2.resize(heatmap,(256,256),interpolation = cv2.INTER_NEAREST)\n",
    "    heatmap_img = cv2.resize(heatmap,(256,256),interpolation = cv2.INTER_NEAREST)\n",
    "    bg = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "    if greyscale == True:\n",
    "        matrix = (0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0)\n",
    "        bg = bg.convert('RGB',matrix)\n",
    "    fg = Image.fromarray(heatmap_img.astype('uint8')).convert('RGB')\n",
    "    outIm = np.array(Image.blend(bg,fg,alpha=0.5))\n",
    "    return outIm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image_and_heatmap_hsv(img,heatmap,norm,greyscale = True):\n",
    "    \"\"\"\n",
    "    Takes in a numpy array for an image and the similarity heatmap.\n",
    "    Blends the two images together and returns a np array of the blended image.\n",
    "    \"\"\"\n",
    "    cmap='jet'\n",
    "    heatmap = cv2.resize(heatmap,(256,256),interpolation = cv2.INTER_NEAREST )\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    heatmap = cmap(1-heatmap)\n",
    "    heatmap *= 255.\n",
    "    norm = cv2.resize(norm,(256,256),interpolation = cv2.INTER_NEAREST )\n",
    "    norm = norm-norm.min()\n",
    "    norm /= norm.max()\n",
    "    heatmap[:,:,3] = norm*255.0\n",
    "    bg = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "    if greyscale == True:\n",
    "        matrix = (0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0)\n",
    "        bg = bg.convert('RGB',matrix)\n",
    "    bg = bg.convert(\"RGBA\")\n",
    "    fg = Image.fromarray(heatmap.astype('uint8')).convert('RGBA')\n",
    "    outIm = np.array(Image.alpha_composite(bg, fg))\n",
    "    return outIm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image_and_heatmap_greyscale(norm,greyscale = True):\n",
    "    \"\"\"\n",
    "    Takes in a numpy array for an image and the similarity heatmap.\n",
    "    Blends the two images together and returns a np array of the blended image.\n",
    "    \"\"\"\n",
    "    norm = norm-norm.min()\n",
    "    norm = norm/norm.max()*255.0\n",
    "    heatmap_img = cv2.resize(norm,(256,256),interpolation = cv2.INTER_NEAREST)\n",
    "    #heatmap_img = cv2.resize(heatmap,(256,256))\n",
    "#     bg = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "#     if greyscale == True:\n",
    "#         matrix = (0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0)\n",
    "#         bg = bg.convert('RGB',matrix)\n",
    "    fg = Image.fromarray(heatmap_img.astype('uint8'),'L')\n",
    "    outIm = np.array(fg)\n",
    "    return outIm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image_and_heatmap_nocmap(img,heatmap,greyscale = True):\n",
    "    \"\"\"\n",
    "    Takes in a numpy array for an image and the similarity heatmap.\n",
    "    Blends the two images together and returns a np array of the blended image.\n",
    "    \"\"\"\n",
    "    heatmap_img = cv2.resize(heatmap,(256,256),interpolation = cv2.INTER_NEAREST)\n",
    "    #heatmap_img = cv2.resize(heatmap,(256,256))\n",
    "    bg = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
    "    if greyscale == True:\n",
    "        matrix = (0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0, 0.2, 0.5, 0.3, 0.0)\n",
    "        bg = bg.convert('RGB',matrix)\n",
    "    fg = Image.fromarray(heatmap_img.astype('uint8')).convert('RGB')\n",
    "    outIm = np.array(Image.blend(bg,fg,alpha=0.5))\n",
    "    return outIm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_visual(grad_cam,feats,allactMaps,queryInd,resultInds,labels):\n",
    "        queryHms = []\n",
    "        resultHms = []\n",
    "        resultImgs = []\n",
    "        query_input_Img = ImageReader.__getitem__(dsets2, queryInd)['data']\n",
    "        queryImg = np.array(query_input_Img)\n",
    "        query_input_Img = data_transforms(query_input_Img.copy()).unsqueeze(0)\n",
    "        feat1 = feats[queryInd]\n",
    "        norm1 = allactMaps[queryInd]\n",
    "\n",
    "        for resultInd in resultInds:\n",
    "            result_input_Img = ImageReader.__getitem__(dsets2, resultInd)['data']\n",
    "            resultImg = np.array(result_input_Img)\n",
    "            feat2 = feats[resultInd]\n",
    "            norm2 = allactMaps[resultInd]\n",
    "                    \n",
    "            result_input_Img = data_transforms(result_input_Img.copy()).unsqueeze(0)\n",
    "            sim1 = grad_cam(query_input_Img, feat2)\n",
    "            sim2 = grad_cam(result_input_Img, feat1)\n",
    "            im1_with_similarity = combine_image_and_heatmap(queryImg,sim1,sim1.min(),sim1.max())\n",
    "            im2_with_similarity = combine_image_and_heatmap(resultImg,sim2,sim2.min(),sim2.max())\n",
    "\n",
    "            queryHms.append(im1_with_similarity)\n",
    "            resultHms.append(im2_with_similarity)\n",
    "            if labels[resultInd] == labels[queryInd]:\n",
    "                resultImgs.append(add_green_border(resultImg))\n",
    "            else:\n",
    "                resultImgs.append(add_red_border(resultImg))\n",
    "            #nn_maps[idx].append(sim1)\n",
    "        \n",
    "        queryHmImgs = combine_horz(queryHms)\n",
    "        resultHmImgs = combine_horz(resultHms)\n",
    "        resultImgs = combine_horz(resultImgs)\n",
    "        stackedImg = combine_vert([np.array(queryHmImgs),np.array(resultImgs),np.array(resultHmImgs)])\n",
    "        leftImg = combine_vert([np.zeros((queryImg.shape)),queryImg,np.zeros((queryImg.shape))])\n",
    "        outImg = combine_horz([np.array(leftImg),np.array(stackedImg)])\n",
    "        return outImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sim_ims_abby(weighs,feats,computer_similarity_method,allMaps,queryInd,resultInds,labels,minVal,maxVal):\n",
    "        queryHms = []\n",
    "        resultHms = []\n",
    "        resultImgs = []\n",
    "        queryImg = np.array(ImageReader.__getitem__(dsets2, queryInd)['data'])\n",
    "        conv1 = allMaps[queryInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "        feat1 = feats[queryInd]\n",
    "\n",
    "        for resultInd in resultInds:\n",
    "            resultImg = np.array(ImageReader.__getitem__(dsets2, resultInd)['data'])\n",
    "            conv2 = allMaps[resultInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "            feat2 = feats[resultInd]\n",
    "            kwargs = {\"conv1\" : conv1, \"conv2\" : conv2} \n",
    "            sim1,sim2 = computer_similarity_method(**kwargs)\n",
    "            \n",
    "            im1_with_similarity = combine_image_and_heatmap(queryImg,sim1,sim1.min(),sim1.max())\n",
    "            im2_with_similarity = combine_image_and_heatmap(resultImg,sim2,sim2.min(),sim2.max())\n",
    "            if resultInd == resultInds[0]:\n",
    "                selfSimQ = sim1\n",
    "                selfSimR = sim2\n",
    "\n",
    "            queryHms.append(im1_with_similarity)\n",
    "            resultHms.append(im2_with_similarity)\n",
    "            if labels[resultInd] == labels[queryInd]:\n",
    "                resultImgs.append(resultImg)\n",
    "            else:\n",
    "                resultImgs.append(add_red_border(resultImg))\n",
    "            #nn_maps[idx].append(sim1)\n",
    "        \n",
    "        queryHmImgs = combine_horz(queryHms)\n",
    "        resultHmImgs = combine_horz(resultHms)\n",
    "        resultImgs = combine_horz(resultImgs)\n",
    "        stackedImg = combine_vert([np.array(queryHmImgs),np.array(resultImgs),np.array(resultHmImgs)])\n",
    "        leftImg = combine_vert([np.zeros((queryImg.shape)),queryImg,np.zeros((queryImg.shape))])\n",
    "        outImg = combine_horz([np.array(leftImg),np.array(stackedImg)])\n",
    "        return outImg, selfSimQ, selfSimR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sim_ims_rgb(weighs,feats,computer_similarity_method,allMaps,queryInd,resultInds,labels,minVal,maxVal):\n",
    "        queryHms = []\n",
    "        resultHms = []\n",
    "        resultImgs = []\n",
    "        queryImg = np.array(ImageReader.__getitem__(dsets2, queryInd)['data'])\n",
    "        conv1 = allMaps[queryInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "        feat1 = feats[queryInd]\n",
    "\n",
    "        for resultInd in resultInds:\n",
    "            resultImg = np.array(ImageReader.__getitem__(dsets2, resultInd)['data'])\n",
    "            conv2 = allMaps[resultInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "            feat2 = feats[resultInd]\n",
    "            kwargs = {\"conv1\" : conv1, \"conv2\" : conv2} \n",
    "            sim1,sim2 = computer_similarity_method(**kwargs)\n",
    "            \n",
    "            im1_with_similarity = combine_image_and_heatmap_nocmap(queryImg,sim1)\n",
    "            im2_with_similarity = combine_image_and_heatmap_nocmap(resultImg,sim2)\n",
    "            if resultInd == resultInds[0]:\n",
    "                selfSimQ = sim1\n",
    "                selfSimR = sim2\n",
    "\n",
    "            queryHms.append(im1_with_similarity)\n",
    "            resultHms.append(im2_with_similarity)\n",
    "            if labels[resultInd] == labels[queryInd]:\n",
    "                resultImgs.append(resultImg)\n",
    "            else:\n",
    "                resultImgs.append(add_red_border(resultImg))\n",
    "            #nn_maps[idx].append(sim1)\n",
    "        \n",
    "        queryHmImgs = combine_horz(queryHms)\n",
    "        resultHmImgs = combine_horz(resultHms)\n",
    "        resultImgs = combine_horz(resultImgs)\n",
    "        stackedImg = combine_vert([np.array(queryHmImgs),np.array(resultImgs),np.array(resultHmImgs)])\n",
    "        leftImg = combine_vert([np.zeros((queryImg.shape)),queryImg,np.zeros((queryImg.shape))])\n",
    "        outImg = combine_horz([np.array(leftImg),np.array(stackedImg)])\n",
    "        return outImg, selfSimQ, selfSimR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_sim_ims_svdwhole_4loss(computer_similarity_method,allMaps,resultInds,labels,minVal,maxVal):        \n",
    "        convlist1=[]\n",
    "        convlist2=[]\n",
    "        convlist3=[]\n",
    "        convlist4=[]\n",
    "        imglist=[]\n",
    "        for resultInd in resultInds:\n",
    "            resultImg = np.array(ImageReader.__getitem__(dsets2, resultInd)['data'])\n",
    "            conv1 = allMaps[0][resultInd].reshape((allMaps[0][0].shape[0]*allMaps[0][0].shape[1],allMaps[0][0].shape[2]))\n",
    "            conv2 = allMaps[1][resultInd].reshape((allMaps[0][0].shape[0]*allMaps[0][0].shape[1],allMaps[0][0].shape[2]))\n",
    "            conv3 = allMaps[2][resultInd].reshape((allMaps[0][0].shape[0]*allMaps[0][0].shape[1],allMaps[0][0].shape[2]))\n",
    "            conv4 = allMaps[3][resultInd].reshape((allMaps[0][0].shape[0]*allMaps[0][0].shape[1],allMaps[0][0].shape[2]))\n",
    "            convlist1.append(conv1)\n",
    "            convlist2.append(conv2)\n",
    "            convlist3.append(conv3)\n",
    "            convlist4.append(conv4)\n",
    "            imglist.append(resultImg)\n",
    "        kwargs1 = {\"convlist\" : convlist1}\n",
    "        kwargs2 = {\"convlist\" : convlist2}\n",
    "        kwargs3 = {\"convlist\" : convlist3}\n",
    "        kwargs4 = {\"convlist\" : convlist4}\n",
    "        reslist1 = computer_similarity_method(**kwargs1)\n",
    "        reslist2 = computer_similarity_method(**kwargs2)\n",
    "        reslist3 = computer_similarity_method(**kwargs3)\n",
    "        reslist4 = computer_similarity_method(**kwargs4)\n",
    "        resultHms1 = []\n",
    "        resultHms2 = []\n",
    "        resultHms3 = []\n",
    "        resultHms4 = []\n",
    "        for res,img in zip(reslist1,imglist):\n",
    "            im_with_similarity = combine_image_and_heatmap_nocmap(img,res)\n",
    "            resultHms1.append(im_with_similarity)\n",
    "        for res,img in zip(reslist2,imglist):\n",
    "            im_with_similarity = combine_image_and_heatmap_nocmap(img,res)\n",
    "            resultHms2.append(im_with_similarity)\n",
    "        for res,img in zip(reslist3,imglist):\n",
    "            im_with_similarity = combine_image_and_heatmap_nocmap(img,res)\n",
    "            resultHms3.append(im_with_similarity)\n",
    "        for res,img in zip(reslist4,imglist):\n",
    "            im_with_similarity = combine_image_and_heatmap_nocmap(img,res)\n",
    "            resultHms4.append(im_with_similarity)\n",
    "#         if labels[resultInd] == labels[queryInd]:\n",
    "#             resultImgs.append(add_green_border(resultImg))\n",
    "#         else:\n",
    "#             resultImgs.append(add_red_border(resultImg))\n",
    "        #nn_maps[idx].append(sim1)\n",
    "        \n",
    "        resultHmImgs1 = combine_horz(resultHms1)\n",
    "        resultHmImgs2 = combine_horz(resultHms2)\n",
    "        resultHmImgs3 = combine_horz(resultHms3)\n",
    "        resultHmImgs4 = combine_horz(resultHms4)\n",
    "        resultImgs = combine_horz(imglist)\n",
    "        stackedImg = combine_vert([np.array(resultImgs),np.array(resultHmImgs1),np.array(resultHmImgs2),np.array(resultHmImgs3),np.array(resultHmImgs4)])\n",
    "        return stackedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sim_ims_reconsturction(feats,computer_similarity_method,allMaps,allactMaps,queryInd,resultInds,labels,mode = None,dim=0):\n",
    "        queryHms = []\n",
    "        resultHms = []\n",
    "        resultImgs = []\n",
    "        queryImg = np.array(ImageReader.__getitem__(dsets2, queryInd)['data'])\n",
    "        conv1 = allMaps[queryInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "        feat1 = feats[queryInd]\n",
    "        norm1 = allactMaps[queryInd]\n",
    "\n",
    "        for resultInd in resultInds:\n",
    "            resultImg = np.array(ImageReader.__getitem__(dsets2, resultInd)['data'])\n",
    "            conv2 = allMaps[resultInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "            feat2 = feats[resultInd]\n",
    "            norm2 = allactMaps[resultInd]\n",
    "            kwargs = {\"conv1\" : conv1, \"conv2\" : conv2}\n",
    "            if mode == 'svd':\n",
    "                sim1,sim2 = computer_similarity_method(**kwargs)\n",
    "                im1_with_similarity = combine_image_and_heatmap_rgb(queryImg,sim1)\n",
    "                im2_with_similarity = combine_image_and_heatmap_rgb(resultImg,sim2)\n",
    "            elif mode == 'norm':\n",
    "                im1_with_similarity = combine_image_and_heatmap_greyscale(norm1)\n",
    "                im2_with_similarity = combine_image_and_heatmap_greyscale(norm2)\n",
    "            elif mode == 'cmap':\n",
    "                kwargs = {\"conv1\" : conv1, \"conv2\" : conv2,\"dim\" : dim}\n",
    "                sim1,sim2 = computer_similarity_method(**kwargs)\n",
    "                im1_with_similarity = combine_image_and_heatmap_cmap(queryImg,sim1)\n",
    "                im2_with_similarity = combine_image_and_heatmap_cmap(resultImg,sim2)\n",
    "            elif mode =='test':\n",
    "                sim1,sim2 = computer_similarity_method(**kwargs)\n",
    "                im1_with_similarity = combine_image_and_heatmap_cmap(queryImg,sim1)\n",
    "                im2_with_similarity = combine_image_and_heatmap_cmap(resultImg,sim2)\n",
    "            else:\n",
    "                sim1,sim2 = computer_similarity_method(**kwargs)\n",
    "\n",
    "                im1_with_similarity = combine_image_and_heatmap_hsv(queryImg,sim1,norm1)\n",
    "                #im1_with_similarity = combine_image_and_heatmap(queryImg,sim1,sim1.min(),sim2.max())\n",
    "                im2_with_similarity = combine_image_and_heatmap_hsv(resultImg,sim2,norm2)\n",
    "            #im2_with_similarity = combine_image_and_heatmap(resultImg,norm2,norm2.min(),norm2.max())\n",
    "\n",
    "            queryHms.append(im1_with_similarity)\n",
    "            resultHms.append(im2_with_similarity)\n",
    "            if labels[resultInd] == labels[queryInd]:\n",
    "                resultImgs.append(add_green_border(resultImg))\n",
    "            else:\n",
    "                resultImgs.append(add_red_border(resultImg))\n",
    "            #nn_maps[idx].append(sim1)\n",
    "        \n",
    "        queryHmImgs = combine_horz(queryHms)\n",
    "        resultHmImgs = combine_horz(resultHms)\n",
    "        resultImgs = combine_horz(resultImgs)\n",
    "        stackedImg = combine_vert([np.array(queryHmImgs),np.array(resultImgs),np.array(resultHmImgs)])\n",
    "        leftImg = combine_vert([np.zeros((queryImg.shape)),queryImg,np.zeros((queryImg.shape))])\n",
    "        outImg = combine_horz([np.array(leftImg),np.array(stackedImg)])\n",
    "        return outImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_sim_ims_svdwhole(feats,computer_similarity_method,allMaps,resultInds,labels,minVal,maxVal):        \n",
    "        convlist=[]\n",
    "        imglist=[]\n",
    "        for resultInd in resultInds:\n",
    "            resultImg = np.array(ImageReader.__getitem__(dsets2, resultInd)['data'])\n",
    "            conv2 = allMaps[resultInd].reshape((allMaps[0].shape[0]*allMaps[0].shape[1],allMaps[0].shape[2]))\n",
    "            feat2 = feats[resultInd]\n",
    "            convlist.append(conv2)\n",
    "            imglist.append(resultImg)\n",
    "        kwargs = {\"convlist\" : convlist}\n",
    "        reslist = computer_similarity_method(**kwargs)\n",
    "        resultHms = []\n",
    "        for res,img in zip(reslist,imglist):\n",
    "            im_with_similarity = combine_image_and_heatmap_nocmap(img,res)\n",
    "            resultHms.append(im_with_similarity)\n",
    "#         if labels[resultInd] == labels[queryInd]:\n",
    "#             resultImgs.append(add_green_border(resultImg))\n",
    "#         else:\n",
    "#             resultImgs.append(add_red_border(resultImg))\n",
    "        #nn_maps[idx].append(sim1)\n",
    "        \n",
    "        resultHmImgs = combine_horz(resultHms)\n",
    "        resultImgs = combine_horz(imglist)\n",
    "        stackedImg = combine_vert([np.array(resultImgs),np.array(resultHmImgs)])\n",
    "        return stackedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Data = 'CAR'\n",
    "maps = []\n",
    "for loss in ['ArcFace','Triplet','ProxyNCA','MultiSimilarity']:\n",
    "    maps.append(torch.load(os.path.join(Data,'savedata',tra_or_val,loss)+'maps.pth'))\n",
    "labels = torch.load(os.path.join(Data,'savedata',tra_or_val,'ArcFace')+'labels.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Data = 'CUB'\n",
    "data_dict = torch.load('/pless_nfs/home/datasets/'+Data+'/data_dict_emb.pth')\n",
    "# src='/pless_nfs/home/datasets/'+Data+'/data_e/'##\n",
    "# data_dict = {p:{os.path.basename(d):glob(d+'/*.jpg') for d in glob(src+p+'/*')} for p in ['tra', 'val']}\n",
    "\n",
    "embed_size=256\n",
    "\n",
    "data_transforms = transforms.Compose([ConvertToBGR(),\n",
    "                                      transforms.Resize(227),\n",
    "                                      transforms.CenterCrop(227),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      Multiplier(255),\n",
    "                                      transforms.Normalize(RGBmean['Imagenet'], RGBstdv['Imagenet'])])\n",
    "\n",
    "data_transforms2 = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(256)])\n",
    "dsets2 = ImageReader(data_dict[tra_or_val], data_transforms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Data = 'CAR'\n",
    "loss = 'ArcFace'\n",
    "feats_epshn = torch.load(os.path.join(Data,'savedata',tra_or_val,loss)+'feats.pth')\n",
    "maps_epshn = torch.load(os.path.join(Data,'savedata',tra_or_val,loss)+'maps.pth')\n",
    "labels = torch.load(os.path.join(Data,'savedata',tra_or_val,'ArcFace')+'labels.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "from similarity_ops import *\n",
    "\n",
    "numResults = 20\n",
    "computer_similarity_method = SVD_whole\n",
    "\n",
    "output_folder = os.path.join(Data,'SVD_wholeclass_four_14',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in set(labels):\n",
    "    sameClassInds = np.where(labels==idx)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "    \n",
    "    res_map= make_sim_ims_svdwhole_4loss(computer_similarity_method,maps4,sameClassInds,labels,0,0)\n",
    "    res_map.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw,ImageFont\n",
    "def img_with_txt(txt):\n",
    "    img = Image.new('RGB', (256, 256), color = 'black')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    w, h = img.size\n",
    "\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/dejavu/DejaVuSerif-Bold.ttf\", 40)\n",
    "    text_w, text_h = draw.textsize(txt, font)\n",
    "\n",
    "    draw.text((10, 150), txt, (255,255,255), font=font)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "importlib.reload(sys.modules['gradcam'])\n",
    "from gradcam import GradCam\n",
    "from similarity_ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WACV2022/Comparison/CAR/val/plus0.jpg\n",
      "WACV2022/Comparison/CAR/val/plus10.jpg\n",
      "WACV2022/Comparison/CAR/val/plus20.jpg\n",
      "WACV2022/Comparison/CAR/val/plus30.jpg\n",
      "WACV2022/Comparison/CAR/val/plus40.jpg\n",
      "WACV2022/Comparison/CAR/val/plus50.jpg\n",
      "WACV2022/Comparison/CAR/val/plus60.jpg\n",
      "WACV2022/Comparison/CAR/val/plus70.jpg\n",
      "WACV2022/Comparison/CAR/val/plus80.jpg\n",
      "WACV2022/Comparison/CAR/val/plus90.jpg\n",
      "WACV2022/Comparison/CAR/val/plus100.jpg\n",
      "WACV2022/Comparison/CAR/val/plus110.jpg\n",
      "WACV2022/Comparison/CAR/val/plus120.jpg\n",
      "WACV2022/Comparison/CAR/val/plus130.jpg\n",
      "WACV2022/Comparison/CAR/val/plus140.jpg\n",
      "WACV2022/Comparison/CAR/val/plus150.jpg\n",
      "WACV2022/Comparison/CAR/val/plus160.jpg\n",
      "WACV2022/Comparison/CAR/val/plus170.jpg\n",
      "WACV2022/Comparison/CAR/val/plus180.jpg\n",
      "WACV2022/Comparison/CAR/val/plus190.jpg\n",
      "WACV2022/Comparison/CAR/val/plus200.jpg\n",
      "WACV2022/Comparison/CAR/val/plus210.jpg\n",
      "WACV2022/Comparison/CAR/val/plus220.jpg\n",
      "WACV2022/Comparison/CAR/val/plus230.jpg\n",
      "WACV2022/Comparison/CAR/val/plus240.jpg\n",
      "WACV2022/Comparison/CAR/val/plus250.jpg\n",
      "WACV2022/Comparison/CAR/val/plus260.jpg\n",
      "WACV2022/Comparison/CAR/val/plus270.jpg\n",
      "WACV2022/Comparison/CAR/val/plus280.jpg\n",
      "WACV2022/Comparison/CAR/val/plus290.jpg\n",
      "WACV2022/Comparison/CAR/val/plus300.jpg\n",
      "WACV2022/Comparison/CAR/val/plus310.jpg\n",
      "WACV2022/Comparison/CAR/val/plus320.jpg\n",
      "WACV2022/Comparison/CAR/val/plus330.jpg\n",
      "WACV2022/Comparison/CAR/val/plus340.jpg\n",
      "WACV2022/Comparison/CAR/val/plus350.jpg\n",
      "WACV2022/Comparison/CAR/val/plus360.jpg\n",
      "WACV2022/Comparison/CAR/val/plus370.jpg\n",
      "WACV2022/Comparison/CAR/val/plus380.jpg\n",
      "WACV2022/Comparison/CAR/val/plus390.jpg\n",
      "WACV2022/Comparison/CAR/val/plus400.jpg\n",
      "WACV2022/Comparison/CAR/val/plus410.jpg\n",
      "WACV2022/Comparison/CAR/val/plus420.jpg\n",
      "WACV2022/Comparison/CAR/val/plus430.jpg\n",
      "WACV2022/Comparison/CAR/val/plus440.jpg\n",
      "WACV2022/Comparison/CAR/val/plus450.jpg\n",
      "WACV2022/Comparison/CAR/val/plus460.jpg\n",
      "WACV2022/Comparison/CAR/val/plus470.jpg\n",
      "WACV2022/Comparison/CAR/val/plus480.jpg\n",
      "WACV2022/Comparison/CAR/val/plus490.jpg\n",
      "WACV2022/Comparison/CAR/val/plus500.jpg\n",
      "WACV2022/Comparison/CAR/val/plus510.jpg\n",
      "WACV2022/Comparison/CAR/val/plus520.jpg\n",
      "WACV2022/Comparison/CAR/val/plus530.jpg\n",
      "WACV2022/Comparison/CAR/val/plus540.jpg\n",
      "WACV2022/Comparison/CAR/val/plus550.jpg\n",
      "WACV2022/Comparison/CAR/val/plus560.jpg\n",
      "WACV2022/Comparison/CAR/val/plus570.jpg\n",
      "WACV2022/Comparison/CAR/val/plus580.jpg\n",
      "WACV2022/Comparison/CAR/val/plus590.jpg\n",
      "WACV2022/Comparison/CAR/val/plus600.jpg\n",
      "WACV2022/Comparison/CAR/val/plus610.jpg\n",
      "WACV2022/Comparison/CAR/val/plus620.jpg\n",
      "WACV2022/Comparison/CAR/val/plus630.jpg\n",
      "WACV2022/Comparison/CAR/val/plus640.jpg\n",
      "WACV2022/Comparison/CAR/val/plus650.jpg\n",
      "WACV2022/Comparison/CAR/val/plus660.jpg\n",
      "WACV2022/Comparison/CAR/val/plus670.jpg\n",
      "WACV2022/Comparison/CAR/val/plus680.jpg\n",
      "WACV2022/Comparison/CAR/val/plus690.jpg\n",
      "WACV2022/Comparison/CAR/val/plus700.jpg\n",
      "WACV2022/Comparison/CAR/val/plus710.jpg\n",
      "WACV2022/Comparison/CAR/val/plus720.jpg\n",
      "WACV2022/Comparison/CAR/val/plus730.jpg\n",
      "WACV2022/Comparison/CAR/val/plus740.jpg\n",
      "WACV2022/Comparison/CAR/val/plus750.jpg\n",
      "WACV2022/Comparison/CAR/val/plus760.jpg\n",
      "WACV2022/Comparison/CAR/val/plus770.jpg\n",
      "WACV2022/Comparison/CAR/val/plus780.jpg\n",
      "WACV2022/Comparison/CAR/val/plus790.jpg\n",
      "WACV2022/Comparison/CAR/val/plus800.jpg\n",
      "WACV2022/Comparison/CAR/val/plus810.jpg\n",
      "WACV2022/Comparison/CAR/val/plus820.jpg\n",
      "WACV2022/Comparison/CAR/val/plus830.jpg\n",
      "WACV2022/Comparison/CAR/val/plus840.jpg\n",
      "WACV2022/Comparison/CAR/val/plus850.jpg\n",
      "WACV2022/Comparison/CAR/val/plus860.jpg\n",
      "WACV2022/Comparison/CAR/val/plus870.jpg\n",
      "WACV2022/Comparison/CAR/val/plus880.jpg\n",
      "WACV2022/Comparison/CAR/val/plus890.jpg\n",
      "WACV2022/Comparison/CAR/val/plus900.jpg\n",
      "WACV2022/Comparison/CAR/val/plus910.jpg\n",
      "WACV2022/Comparison/CAR/val/plus920.jpg\n",
      "WACV2022/Comparison/CAR/val/plus930.jpg\n",
      "WACV2022/Comparison/CAR/val/plus940.jpg\n",
      "WACV2022/Comparison/CAR/val/plus950.jpg\n",
      "WACV2022/Comparison/CAR/val/plus960.jpg\n",
      "WACV2022/Comparison/CAR/val/plus970.jpg\n",
      "WACV2022/Comparison/CAR/val/plus980.jpg\n",
      "WACV2022/Comparison/CAR/val/plus990.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1000.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1010.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1020.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1030.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1040.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1050.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1060.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1070.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1080.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1090.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1100.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1110.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1120.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1130.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1140.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1150.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1160.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1170.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1180.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1190.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1200.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1210.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1220.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1230.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1240.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1250.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1260.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1270.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1280.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1290.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1300.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1310.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1320.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1330.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1340.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1350.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1360.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1370.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1380.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1390.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1400.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1410.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1420.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1430.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1440.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1450.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1460.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1470.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1480.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1490.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1500.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1510.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1520.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1530.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1540.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1550.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1560.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1570.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1580.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1590.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1600.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1610.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1620.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1630.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1640.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1650.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1660.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1670.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1680.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1690.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1700.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1710.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1720.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1730.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1740.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1750.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1760.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1770.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1780.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1790.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1800.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1810.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1820.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1830.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1840.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1850.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1860.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1870.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1880.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1890.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1900.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1910.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1920.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1930.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1940.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1950.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1960.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1970.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1980.jpg\n",
      "WACV2022/Comparison/CAR/val/plus1990.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2000.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2010.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2020.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2030.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2040.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2050.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2060.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2070.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2080.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2090.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2100.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2110.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2120.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2130.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2140.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2150.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2160.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2170.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2180.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2190.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2200.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2210.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2220.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2230.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2240.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2250.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2260.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2270.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2280.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2290.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2300.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2310.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2320.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2330.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2340.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2350.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2360.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2370.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2380.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2390.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2400.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2410.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2420.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2430.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2440.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2450.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2460.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2470.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2480.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2490.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2500.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2510.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2520.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2530.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2540.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2550.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2560.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2570.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2580.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2590.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2600.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2610.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2620.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2630.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2640.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2650.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2660.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2670.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2680.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2690.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2700.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2710.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2720.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2730.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2740.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2750.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2760.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2770.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2780.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2790.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2800.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2810.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2820.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2830.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2840.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2850.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2860.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2870.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2880.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2890.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2900.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2910.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2920.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2930.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2940.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2950.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2960.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2970.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2980.jpg\n",
      "WACV2022/Comparison/CAR/val/plus2990.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3000.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3010.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3020.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3030.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3040.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3050.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3060.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3070.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3080.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3090.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3100.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3110.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3120.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3130.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3140.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3150.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3160.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3170.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3180.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3190.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3200.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3210.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3220.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3230.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3240.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3250.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3260.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3270.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3280.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3290.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3300.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3310.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3320.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3330.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3340.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3350.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3360.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3370.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3380.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3390.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3400.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3410.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3420.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3430.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3440.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3450.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3460.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3470.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3480.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3490.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3500.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3510.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3520.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3530.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3540.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3550.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3560.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3570.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3580.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3590.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3600.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3610.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3620.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3630.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3640.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3650.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3660.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3670.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3680.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3690.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3700.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3710.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3720.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3730.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3740.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3750.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3760.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3770.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3780.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3790.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3800.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3810.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3820.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3830.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3840.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3850.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3860.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3870.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3880.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3890.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3900.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3910.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3920.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3930.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3940.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3950.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3960.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3970.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3980.jpg\n",
      "WACV2022/Comparison/CAR/val/plus3990.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4000.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4010.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4020.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4030.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4040.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4050.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4060.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4070.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4080.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4090.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4100.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4110.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4120.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4130.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4140.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4150.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4160.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4170.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4180.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4190.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4200.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4210.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4220.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4230.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4240.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4250.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4260.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4270.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4280.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4290.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4300.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4310.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4320.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4330.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4340.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4350.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4360.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4370.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4380.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4390.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4400.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4410.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4420.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4430.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4440.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4450.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4460.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4470.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4480.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4490.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4500.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4510.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4520.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4530.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4540.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4550.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4560.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4570.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4580.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4590.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4600.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4610.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4620.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4630.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4640.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4650.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4660.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4670.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4680.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4690.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4700.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4710.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4720.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4730.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4740.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4750.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4760.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4770.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4780.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4790.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4800.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4810.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4820.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4830.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4840.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4850.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4860.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4870.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4880.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4890.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4900.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4910.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4920.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4930.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4940.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4950.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4960.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4970.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4980.jpg\n",
      "WACV2022/Comparison/CAR/val/plus4990.jpg\n"
     ]
    }
   ],
   "source": [
    "numResults = 20\n",
    "computer_similarity_method_3 = SVD_reconstruction_thres\n",
    "computer_similarity_method_2 = compute_spatial_similarity\n",
    "computer_similarity_method_1 = combine_SVD\n",
    "\n",
    "output_folder = os.path.join('WACV2022','Comparison','CAR','val')\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in range(0,5000,10):\n",
    "#for idx in [2680]:\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,'plus'+str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "\n",
    "    sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "\n",
    "    epshn_epshn_nearest_imgs1 = combine_horz([np.array(img_with_txt((str(queryCls)))),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map1, s1_arcface, s2_arcface = make_sim_ims_abby(0,feats_epshn,computer_similarity_method_2,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_nearest_imgs1),np.array(epshn_nearest_map1)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs2 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map2, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method_1,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs2),np.array(epshn_nearest_map2)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs3 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map3 = grad_cam_visual(grad_cam,feats_epshn,act_map,idx,sortedInds_epshn_nearest,labels)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_nearest_imgs2),np.array(epshn_nearest_map3)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map = make_sim_ims_reconsturction(feats_epshn,computer_similarity_method_3,maps_epshn,act_map,idx,sortedInds_epshn_nearest,labels,mode = None,dim=0)\n",
    "    img3 = combine_vert([np.array(epshn_epshn_nearest_imgs),np.array(epshn_nearest_map)])\n",
    " \n",
    "    outImg = combine_vert([np.array(img2),np.zeros((10,epshn_nearest_map2.width)),np.array(img0),np.zeros((10,epshn_nearest_map2.width)),np.array(img1),np.zeros((10,epshn_nearest_map2.width)),np.array(img3)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_or_val='tra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numResults = 20\n",
    "computer_similarity_method = combine_SVD\n",
    "\n",
    "output_folder = os.path.join(Data,'training_14*14',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "epshn_maps = maps[-1]\n",
    "epshn_maps = {}\n",
    "feats_epshn = feats[-1]\n",
    "feats_0 = feats[0]\n",
    "#arcface_maps = {}\n",
    "for idx in range(0,5000,10):\n",
    "#for idx in [10]:\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    epshn_feat_0  = feats_0[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "\n",
    "    dists_0 = [np.dot(epshn_feat_0/np.linalg.norm(epshn_feat_0),f/np.linalg.norm(f)) for f in feats_0]\n",
    "    dists_0 = np.array(dists_0)\n",
    "    sortedInds_0= np.argsort(-dists_0)\n",
    "    #sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_0_nearest = sortedInds_0[:numResults]\n",
    "    \n",
    "#     print(sortedInds_0_nearest)\n",
    "#     print(sortedInds_epshn_nearest)\n",
    "    \n",
    "#     out = sortedInds_0_nearest[sortedInds_epshn_nearest[np.searchsorted(sortedInds_epshn_nearest,sortedInds_0_nearest)] != sortedInds_0_nearest]\n",
    "#     print(out)\n",
    "\n",
    "    reslist=[2519,2658,2554,2660,2474,2542,2704,2555,2767,45,2566,2677,2706,2507,31,37]\n",
    "    #reslist = [2519]\n",
    "#     for item in out:\n",
    "#         if label[out]!=label[idx]:\n",
    "#             print(item)\n",
    "#             reslist.append(item)\n",
    "    \n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "    \n",
    "    epshn_epshn_nearest_imgs0 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map0, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats[0],computer_similarity_method,maps[0],idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_nearest_imgs0),np.array(epshn_nearest_map0)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs1 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map1, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats[1],computer_similarity_method,maps[1],idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs1),np.array(epshn_nearest_map1)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs2 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map2, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats[2],computer_similarity_method,maps[2],idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_nearest_imgs2),np.array(epshn_nearest_map2)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs3 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map3, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats[3],computer_similarity_method,maps[3],idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img3 = combine_vert([np.array(epshn_epshn_nearest_imgs3),np.array(epshn_nearest_map3)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs4 = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map4, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats[4],computer_similarity_method,maps[4],idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img4 = combine_vert([np.array(epshn_epshn_nearest_imgs4),np.array(epshn_nearest_map4)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,epshn_nearest_map4.width)),np.array(img1),np.zeros((10,epshn_nearest_map4.width)),np.array(img2),np.zeros((10,epshn_nearest_map4.width)),np.array(img3),np.zeros((10,epshn_nearest_map4.width)),np.array(img4)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[2519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numResults = 20\n",
    "computer_similarity_method = combine_SVD\n",
    "\n",
    "output_folder = os.path.join(Data,'PCA_training','combine_SVD',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "pca_maps = {}\n",
    "ori_maps = {}\n",
    "for idx in range(0,5000,10):\n",
    "#for idx in [120]:\n",
    "#for idx in range(0,5000,10):\n",
    "    pca_maps[idx] = []\n",
    "    ori_maps[idx] = []\n",
    "    \n",
    "    pca_feat = feats_pca[idx]\n",
    "    ori_feat = feats_ori[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "    # arcface dists\n",
    "    dists_ori = [np.dot(ori_feat/np.linalg.norm(ori_feat),f/np.linalg.norm(f)) for f in feats_ori]\n",
    "    dists_ori = np.array(dists_ori)\n",
    "    sortedInds_ori = np.argsort(-dists_ori)\n",
    "\n",
    "    # epshn dists\n",
    "    dists_pca = [np.dot(pca_feat/np.linalg.norm(pca_feat),f/np.linalg.norm(f)) for f in feats_pca]\n",
    "    dists_pca = np.array(dists_pca)\n",
    "    sortedInds_pca= np.argsort(-dists_pca)\n",
    "    \n",
    "    sortedInds_pca_nearest = sortedInds_pca[:numResults]\n",
    "    sortedInds_ori_nearest = sortedInds_ori[:numResults]\n",
    "    \n",
    "    ori_ori_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_ori[sortedInds_ori_nearest]]))])\n",
    "    ori_ori_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_ori,computer_similarity_method,maps_ori,idx,sortedInds_ori_nearest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(ori_ori_imgs),np.array(ori_ori_map)])\n",
    "    \n",
    "    ori_pca_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_ori[sortedInds_ori_nearest]]))])\n",
    "    ori_pca_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_pca,computer_similarity_method,maps_pca,idx,sortedInds_ori_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(ori_pca_imgs),np.array(ori_pca_map)])\n",
    "\n",
    "    pca_ori_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_pca[sortedInds_pca_nearest]]))])\n",
    "    pca_ori_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_ori,computer_similarity_method,maps_ori,idx,sortedInds_pca_nearest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(pca_ori_imgs),np.array(pca_ori_map)])\n",
    "    \n",
    "    pca_pca_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_pca[sortedInds_pca_nearest]]))])\n",
    "    pca_pca_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_pca,computer_similarity_method,maps_pca,idx,sortedInds_pca_nearest,labels,0,0)\n",
    "    img3 = combine_vert([np.array(pca_pca_imgs),np.array(pca_pca_map)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,ori_ori_imgs.width)),np.array(img1),np.zeros((10,ori_ori_imgs.width)),np.array(img2),np.zeros((10,ori_ori_imgs.width)),np.array(img3)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3242a4b0eb14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mepshn_ori_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_horz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_horz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_with_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%0.5f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdists_epshn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedInds_epshn_nearest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#epshn_ori_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mepshn_ori_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_arcface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_arcface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_sim_ims_reconsturction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_epshn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomputer_similarity_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaps_epshn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msortedInds_epshn_nearest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_vert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepshn_ori_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepshn_ori_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-da579d0f3148>\u001b[0m in \u001b[0;36mmake_sim_ims_reconsturction\u001b[0;34m(feats, computer_similarity_method, allMaps, allactMaps, queryInd, resultInds, labels, mode, dim)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mim2_with_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_image_and_heatmap_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultImg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0msim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputer_similarity_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mim1_with_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_image_and_heatmap_hsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryImg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Comparison_vis/similarity_ops.py\u001b[0m in \u001b[0;36mSVD_reconstruction_thres\u001b[0;34m(conv1, conv2, n_dim)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[0;31m#     #newconv1_r = u1[0]*s[0]*v[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m     \u001b[0mtemp_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m     \u001b[0mproj_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "numResults = 20\n",
    "computer_similarity_method = SVD_reconstruction_thres\n",
    "\n",
    "#output_folder = os.path.join(Data,'PCA_training','reconstruction',tra_or_val)\n",
    "output_folder = os.path.join('CUB_toy')\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "for idx in range(0,5000,1):\n",
    "#for idx in [120]:\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    \n",
    "\n",
    "    epshn_ori_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    #epshn_ori_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    epshn_ori_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(feats_epshn,computer_similarity_method,maps_epshn,act_map,idx,sortedInds_epshn_nearest,labels)\n",
    "    img2 = combine_vert([np.array(epshn_ori_imgs),np.array(epshn_ori_map)])\n",
    "    \n",
    "    \n",
    "    img2.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e329a5598f26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mepshn_epshn_samefurthest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_horz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_horz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_with_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%0.5f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdists_epshn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedInds_epshn_same_furthest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mepshn_samefurthest_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_arcface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_arcface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_sim_ims_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats_epshn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomputer_similarity_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaps_epshn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msortedInds_epshn_same_furthest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_vert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepshn_epshn_samefurthest_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepshn_samefurthest_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-dc0a2e0e2d08>\u001b[0m in \u001b[0;36mmake_sim_ims_rgb\u001b[0;34m(weighs, feats, computer_similarity_method, allMaps, queryInd, resultInds, labels, minVal, maxVal)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mfeat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresultInd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"conv1\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conv2\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"weighs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mweighs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feat1\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfeat1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"feat2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeat2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputer_similarity_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mim1_with_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_image_and_heatmap_nocmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryImg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Comparison_vis/similarity_ops.py\u001b[0m in \u001b[0;36mcombine_SVD\u001b[0;34m(conv1, conv2, weighs, feat1, feat2)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0mallconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0mallconv\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mallconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;31m#     u1, s, v= np.linalg.svd(conv1, full_matrices=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;31m#     u2, _, _ = np.linalg.svd(conv2, full_matrices=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "numResults = 20\n",
    "computer_similarity_method = combine_SVD\n",
    "\n",
    "output_folder = os.path.join(Data,'combine_SVD_14*14',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in range(1000,5000,10):\n",
    "#for idx in [120]:\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "\n",
    "    sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "    \n",
    "    epshn_epshn_furthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_furthest]]))])\n",
    "    epshn_furthest_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_furthest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_furthest_imgs),np.array(epshn_furthest_map)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs),np.array(epshn_nearest_map)])\n",
    "    \n",
    "    epshn_epshn_samefurthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_same_furthest]]))])\n",
    "    epshn_samefurthest_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_same_furthest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_samefurthest_imgs),np.array(epshn_samefurthest_map)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img1),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img2)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "from similarity_ops import *\n",
    "\n",
    "numResults = 20\n",
    "computer_similarity_method = SVD_whole\n",
    "\n",
    "output_folder = os.path.join(Data,'SVD_wholeclass_14*14',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in set(labels):\n",
    "    sameClassInds = np.where(labels==idx)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "    \n",
    "    res_map= make_sim_ims_svdwhole(feats_epshn,computer_similarity_method,maps_epshn,sameClassInds,labels,0,0)\n",
    "    res_map.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "from similarity_ops import *\n",
    "\n",
    "\n",
    "numResults = 20\n",
    "computer_similarity_method = SVD_reconstruction_thres\n",
    "\n",
    "output_folder = os.path.join(Data,'pair_consturction_14*14',tra_or_val)\n",
    "output_fol\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in range(100,5000,10):\n",
    "#for idx in [10]:\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "\n",
    "    sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "    \n",
    "    epshn_epshn_furthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_furthest]]))])\n",
    "    epshn_furthest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_furthest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_furthest_imgs),np.array(epshn_furthest_map)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs),np.array(epshn_nearest_map)])\n",
    "    \n",
    "    epshn_epshn_samefurthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_same_furthest]]))])\n",
    "    epshn_samefurthest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_same_furthest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_samefurthest_imgs),np.array(epshn_samefurthest_map)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img1),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img2)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "from similarity_ops import *\n",
    "\n",
    "\n",
    "numResults = 20\n",
    "computer_similarity_method = SVD_reconstruction_thres\n",
    "\n",
    "output_folder = os.path.join(Data,'test_pair_consturction_14*14',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in range(0,5000,10):\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "\n",
    "    sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "    \n",
    "    epshn_epshn_furthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_furthest]]))])\n",
    "    epshn_furthest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_furthest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_furthest_imgs),np.array(epshn_furthest_map)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs),np.array(epshn_nearest_map)])\n",
    "    \n",
    "    epshn_epshn_samefurthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_same_furthest]]))])\n",
    "    epshn_samefurthest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_same_furthest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_samefurthest_imgs),np.array(epshn_samefurthest_map)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img1),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img2)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_resnet(dsets,whichModel,whichConv):\n",
    "    whichModel.train(False)\n",
    "    dataLoader = torch.utils.data.DataLoader(dsets, batch_size=10, sampler=SequentialSampler(dsets), num_workers=12)\n",
    "    # iterate batch\n",
    "    V,M,L = [],[],[]\n",
    "    modules=list(whichModel.children())[:-2]\n",
    "    whichModel_pool = nn.Sequential(*modules)\n",
    "    whichModel_pool = whichModel_pool.cuda()\n",
    "    for data in dataLoader:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            inputs_bt, labels_bt = data['data'], data['label']  # <FloatTensor> <LongTensor>\n",
    "            fmap_tmp = whichModel_pool(inputs_bt.cuda())\n",
    "            #fvec = whichModel_fc(fmap_tmp)\n",
    "            #fvec = whichModel(inputs_bt.cuda())\n",
    "            # i need a tensor norml2 function here\n",
    "#             fmap = norml2(fc_Conv(fmap_tmp))\n",
    "#             fmap = whichConv(fmap_tmp)\n",
    "            fmap = fmap_tmp\n",
    "            fvec = whichModel(inputs_bt.cuda())\n",
    "            \n",
    "        V.extend(fvec.cpu().numpy())\n",
    "        M.extend(fmap.cpu().numpy())\n",
    "        L.extend(labels_bt.numpy())\n",
    "        \n",
    "    maps_epshn = np.moveaxis(np.array(M),1,3)\n",
    "    feats_epshn = np.array(V)\n",
    "    labels = np.array(L)\n",
    "    for parameter in whichModel.fc.parameters():\n",
    "        epshn_weighs = parameter\n",
    "        break\n",
    "    epshn_weighs=epshn_weighs.cpu().detach().numpy()\n",
    "    return feats_epshn, maps_epshn, labels, epshn_weighs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import PIL\n",
    "data_dict = torch.load('../googlelandmark_epshn/data_dict_landmark.pth')\n",
    "model = torch.load('../googlelandmark_epshn/_result/EPSHN/GoogleLandmark_R101/512/G16/0/model.pth')\n",
    "#model = torch.load('../googlelandmark_epshn/_result/EPSHN/Landmark_R101/512/G16/0/')\n",
    "data_dict_val = data_dict['val']\n",
    "new_data_dict_val = {}\n",
    "for idx,key in enumerate(list(data_dict_val.keys())):\n",
    "    if idx < 300:\n",
    "        pass\n",
    "    if idx > 400:\n",
    "        break\n",
    "    new_data_dict_val[key] = data_dict_val[key]\n",
    "data_dict['val'] = new_data_dict_val\n",
    "\n",
    "data_transforms = transforms.Compose([transforms.Resize(512),\n",
    "                                      transforms.CenterCrop(512),\n",
    "                                      transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "dsets = ImageReader(data_dict['val'], data_transforms)\n",
    "\n",
    "data_transforms2 = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(256)])\n",
    "dsets2 = ImageReader(data_dict['val'], data_transforms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "feats_epshn, maps_epshn, labels, epshn_weighs = embed_resnet(dsets,model,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37274, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_epshn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = 'GoogleLandmark'\n",
    "tra_or_val = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "from similarity_ops import *\n",
    "\n",
    "numResults = 20\n",
    "computer_similarity_method = SVD_whole\n",
    "\n",
    "output_folder = os.path.join(Data,'SVD_wholeclass_16*16',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in set(labels):\n",
    "    sameClassInds = np.where(labels==idx)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "    \n",
    "    res_map= make_sim_ims_svdwhole(feats_epshn,computer_similarity_method,maps_epshn,sameClassInds,labels,0,0)\n",
    "    res_map.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pless_nfs/home/liuxiaotong2017/Comparison_vis/similarity_ops.py:1086: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  temp_1,resid,rank,s = np.linalg.lstsq(v2[0:n_dim].T,conv1.T)\n",
      "/pless_nfs/home/liuxiaotong2017/Comparison_vis/similarity_ops.py:1110: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  temp_2,resid,rank,s = np.linalg.lstsq(v1[0:n_dim].T,conv2.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleLandmark/pair_consturction_16*16/val/0.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/10.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/20.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/30.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/40.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/50.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/60.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/70.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/80.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/90.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/100.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/110.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/120.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/130.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/140.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/150.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/160.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/170.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/180.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/190.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/200.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/210.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/220.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/230.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/240.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/250.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/260.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/270.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/280.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/290.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/300.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/310.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/320.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/330.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/340.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/350.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/360.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/370.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/380.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/390.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/400.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/410.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/420.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/430.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/440.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/450.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/460.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/470.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/480.jpg\n",
      "GoogleLandmark/pair_consturction_16*16/val/490.jpg\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sys.modules['similarity_ops'])\n",
    "from similarity_ops import *\n",
    "\n",
    "\n",
    "numResults = 20\n",
    "computer_similarity_method = SVD_reconstruction_thres\n",
    "\n",
    "output_folder = os.path.join(Data,'pair_consturction_16*16','val')\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in range(0,500,10):\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "\n",
    "    sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "    \n",
    "    epshn_epshn_furthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_furthest]]))])\n",
    "    epshn_furthest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(epshn_weighs,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_furthest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_furthest_imgs),np.array(epshn_furthest_map)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(epshn_weighs,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs),np.array(epshn_nearest_map)])\n",
    "    \n",
    "    epshn_epshn_samefurthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_same_furthest]]))])\n",
    "    epshn_samefurthest_map, s1_arcface, s2_arcface = make_sim_ims_reconsturction(epshn_weighs,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_same_furthest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_samefurthest_imgs),np.array(epshn_samefurthest_map)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img1),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img2)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleLandmark/combine_SVD_16*16/val/0.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/10.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/20.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/30.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/40.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/50.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/60.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/70.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/80.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/90.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/100.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/110.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/120.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/130.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/140.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/150.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/160.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/170.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/180.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/190.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/200.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/210.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/220.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/230.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/240.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/250.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/260.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/270.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/280.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/290.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/300.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/310.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/320.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/330.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/340.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/350.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/360.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/370.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/380.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/390.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/400.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/410.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/420.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/430.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/440.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/450.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/460.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/470.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/480.jpg\n",
      "GoogleLandmark/combine_SVD_16*16/val/490.jpg\n"
     ]
    }
   ],
   "source": [
    "numResults = 20\n",
    "computer_similarity_method = combine_SVD\n",
    "\n",
    "output_folder = os.path.join(Data,'combine_SVD_16*16',tra_or_val)\n",
    "#output_folder = os.path.join(Data,tra_or_val,'top_results')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "epshn_maps = {}\n",
    "#arcface_maps = {}\n",
    "for idx in range(0,500,10):\n",
    "#for idx in range(0,5000,10):\n",
    "    epshn_maps[idx] = []\n",
    "    #arcface_maps[idx] = []\n",
    "    \n",
    "    epshn_feat = feats_epshn[idx]\n",
    "    #arcface_feat = feats_arcface[idx]\n",
    "    queryCls = labels[idx]\n",
    "    sameClassInds = np.where(labels==queryCls)[0]\n",
    "    outFilename = os.path.join(output_folder,str(idx)+'.jpg')\n",
    "\n",
    "#     # arcface dists\n",
    "#     dists_arcface = [np.dot(arcface_feat/np.linalg.norm(arcface_feat),f/np.linalg.norm(f)) for f in feats_arcface]\n",
    "#     dists_arcface = np.array(dists_arcface)\n",
    "#     sortedInds_arcface = np.argsort(-dists_arcface)[:numResults]\n",
    "\n",
    "    # epshn dists\n",
    "    dists_epshn = [np.dot(epshn_feat/np.linalg.norm(epshn_feat),f/np.linalg.norm(f)) for f in feats_epshn]\n",
    "    dists_epshn = np.array(dists_epshn)\n",
    "    sortedInds_epshn= np.argsort(-dists_epshn)\n",
    "    \n",
    "\n",
    "    sortedInds_epshn_furthest = sortedInds_epshn[-numResults:]\n",
    "    sortedInds_epshn_nearest = sortedInds_epshn[:numResults]\n",
    "    sortedInds_epshn_same_furthest = sortedInds_epshn[labels[sortedInds_epshn] == labels[idx]][-10:]\n",
    "    \n",
    "    epshn_epshn_furthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_furthest]]))])\n",
    "    epshn_furthest_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_furthest,labels,0,0)\n",
    "    img0 = combine_vert([np.array(epshn_epshn_furthest_imgs),np.array(epshn_furthest_map)])\n",
    "    \n",
    "    epshn_epshn_nearest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_nearest]]))])\n",
    "    epshn_nearest_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_nearest,labels,0,0)\n",
    "    img1 = combine_vert([np.array(epshn_epshn_nearest_imgs),np.array(epshn_nearest_map)])\n",
    "    \n",
    "    epshn_epshn_samefurthest_imgs = combine_horz([np.zeros((256,256,3)),np.array(combine_horz([np.array(img_with_txt('%0.5f'%(d))) for d in dists_epshn[sortedInds_epshn_same_furthest]]))])\n",
    "    epshn_samefurthest_map, s1_arcface, s2_arcface = make_sim_ims_rgb(0,feats_epshn,computer_similarity_method,maps_epshn,idx,sortedInds_epshn_same_furthest,labels,0,0)\n",
    "    img2 = combine_vert([np.array(epshn_epshn_samefurthest_imgs),np.array(epshn_samefurthest_map)])\n",
    "    \n",
    "    outImg = combine_vert([np.array(img0),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img1),np.zeros((10,epshn_epshn_furthest_imgs.width)),np.array(img2)])\n",
    "    outImg.save(outFilename)\n",
    "    print(outFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
